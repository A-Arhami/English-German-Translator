{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Capstone Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-Arhami/English-German-Translator/blob/main/ENG_to_GER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aio4AmPiEYyT"
      },
      "source": [
        "# Neural translation model\n",
        "\n",
        "In this notebook, a neural network have been implemented that translates from English to German.\n",
        "![Flags overview image](data/germany_uk_flags.png)\n",
        "\n",
        "For the capstone project, I'm using a language dataset from http://www.manythings.org/anki/ to build a neural translation model. This dataset consists of over 200,000 pairs of sentences in English and German. In order to make the training quicker, I will restrict to our dataset to 20,000 pairs.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYW_Xkg8EYyj"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARVqcYRiEYyr",
        "outputId": "622bfa94-d2cc-4d5e-b629-2a60c61f5e29"
      },
      "source": [
        "# Run this cell to load the dataset\n",
        "\n",
        "NUM_EXAMPLES = 20000\n",
        "data_examples = []\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/drive/My Drive/DIGI/deu.txt', 'r', encoding='utf8') as f:\n",
        "    for line in f.readlines():\n",
        "        if len(data_examples) < NUM_EXAMPLES:\n",
        "            data_examples.append(line)\n",
        "        else:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoJUETQ4EYyt"
      },
      "source": [
        "# These functions preprocess English and German sentences\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r\"ü\", 'ue', sentence)\n",
        "    sentence = re.sub(r\"ä\", 'ae', sentence)\n",
        "    sentence = re.sub(r\"ö\", 'oe', sentence)\n",
        "    sentence = re.sub(r'ß', 'ss', sentence)\n",
        "    \n",
        "    sentence = unicode_to_ascii(sentence)\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r\"[^a-z?.!,']+\", \" \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    \n",
        "    return sentence.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiEMYn60EYyw"
      },
      "source": [
        "#### The custom translation model\n",
        "The following is a schematic of the custom translation model architecture I have developed in this project.\n",
        "\n",
        "![Model Schematic](data/neural_translation_model.png)\n",
        "\n",
        "Key:\n",
        "![Model key](data/neural_translation_model_key.png)\n",
        "\n",
        "The custom model consists of an encoder RNN and a decoder RNN. The encoder takes words of an English sentence as input, and uses a pre-trained word embedding to embed the words into a 128-dimensional space. To indicate the end of the input sentence, a special end token (in the same 128-dimensional space) is passed in as an input. This token is a TensorFlow Variable that is learned in the training phase (unlike the pre-trained word embedding, which is frozen).\n",
        "\n",
        "The decoder RNN takes the internal state of the encoder network as its initial state. A start token is passed in as the first input, which is embedded using a learned German word embedding. The decoder RNN then makes a prediction for the next German word, which during inference is then passed in as the following input, and this process is repeated until the special `<end>` token is emitted from the decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmTEyMshEYy0"
      },
      "source": [
        "## 1. Text preprocessing\n",
        "* Creating separate lists of English and German sentences, and preprocess them using the `preprocess_sentence` function provided above.\n",
        "* Adding a special `\"<start>\"` and `\"<end>\"` token to the beginning and end of every German sentence.\n",
        "*  tokenizing the German sentences\n",
        "* Padding the end of the tokenized German sequences with zeros, and batching the complete set of sequences into one numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bJUFVsAsEYy3"
      },
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "for x in data_examples:\n",
        "    x=x.split('\\t')\n",
        "    X.append(preprocess_sentence(x[0]))\n",
        "    Y.append(\"<start>\"+\" \"+preprocess_sentence(x[1])+\" \"+\"<end>\")\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTgLcMk9EYy5"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=None, \n",
        "                                                  filters=[])\n",
        "tokenizer.fit_on_texts(Y)\n",
        "Y_seq= tokenizer.texts_to_sequences(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy8eXGq2EYy8",
        "outputId": "166f0da9-1a11-412e-f63f-6442f079e984"
      },
      "source": [
        "for i in np.random.rand(5)*NUM_EXAMPLES:\n",
        "    print (X[int(i)],Y[int(i)],\"\\n\",Y_seq[int(i)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pick it up . <start> hebe es auf . <end> \n",
            " [1, 1819, 10, 29, 3, 2]\n",
            "you're not alone . <start> du bist nicht allein . <end> \n",
            " [1, 13, 32, 12, 139, 3, 2]\n",
            "what gives ? <start> was ist los ? <end> \n",
            " [1, 38, 6, 207, 7, 2]\n",
            "can you show me ? <start> kannst du es mir zeigen ? <end> \n",
            " [1, 109, 13, 10, 21, 709, 7, 2]\n",
            "why is this ? <start> woran liegt das ? <end> \n",
            " [1, 3383, 353, 11, 7, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G93s7fGFEYzA"
      },
      "source": [
        "Y_seq_padded=tf.keras.preprocessing.sequence.pad_sequences(Y_seq,20,padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPNnU-J8EYzB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaOxlOx6EYzC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4-yvlnPEYzD"
      },
      "source": [
        "## 2. Prepare the data with tf.data.Dataset objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFUweXleEYzF"
      },
      "source": [
        "#### Load the embedding layer\n",
        "As part of the dataset preproceessing for this project, I will use a pre-trained English word embedding module from TensorFlow Hub. The URL for the module is https://tfhub.dev/google/tf2-preview/nnlm-en-dim128-with-normalization/1. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch_KIN1GEYzH"
      },
      "source": [
        "# Load embedding module from Tensorflow Hub\n",
        "embedding_layer = hub.load(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128-with-normalization/1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nO0YVnsEYzI",
        "outputId": "c7e0bdca-6e6f-49e7-8bb9-af97a248ead7"
      },
      "source": [
        "# Test the layer\n",
        "\n",
        "embedding_layer(tf.constant([\"these\", \"aren't\", \"the\", \"droids\", \"you're\", \"looking\", \"for\"])).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([7, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUPbvWWxEYzK"
      },
      "source": [
        "x_train,x_test,y_train,y_test= train_test_split(X,Y_seq_padded,train_size=0.8 )\n",
        "def list_to_dataset(x,y):\n",
        "    return tf.data.Dataset.from_tensor_slices((x,y))\n",
        "train_data=list_to_dataset(x_train,y_train)\n",
        "test_data=list_to_dataset(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKXNidB7EYzM"
      },
      "source": [
        "def map_split(dataset):\n",
        "\n",
        "\n",
        "    def map_func(x, y):\n",
        "\n",
        "        x = tf.strings.split(x)\n",
        "\n",
        "        return (x,y)\n",
        "    mapped_dataset = dataset.map(map_func)\n",
        "    return mapped_dataset    \n",
        "\n",
        "train_data=map_split(train_data)\n",
        "test_data=map_split(test_data)\n",
        "\n",
        "def map_func1(x, y):\n",
        "\n",
        "    x = embedding_layer(x)\n",
        "\n",
        "    return (x,y)\n",
        "\n",
        "train_data = train_data.map(map_func1)\n",
        "test_data = test_data.map(map_func1)\n",
        "\n",
        "\n",
        "train_data = train_data.filter(lambda x, y : len(x) < 14) \n",
        "test_data = test_data.filter(lambda x, y : len(x) < 14) \n",
        "\n",
        "\n",
        "def map_13(x, y): \n",
        "\n",
        "    paddings = tf.constant([[13, 0,], [0, 0]]) \n",
        "\n",
        "    new_x = tf.pad(x, paddings) \n",
        "\n",
        "    return (new_x[-13:,:], y) \n",
        "\n",
        "train_data = train_data.map(map_13) \n",
        "test_data = test_data.map(map_13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd1o-PRFEYzN",
        "outputId": "4e79fe5f-5f31-490d-f1e8-9e5038d82d54"
      },
      "source": [
        "train_data=train_data.batch(16)\n",
        "test_data=test_data.batch(16)\n",
        "\n",
        "train_data.element_spec , test_data.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((TensorSpec(shape=(None, None, 128), dtype=tf.float32, name=None),\n",
              "  TensorSpec(shape=(None, 20), dtype=tf.int32, name=None)),\n",
              " (TensorSpec(shape=(None, None, 128), dtype=tf.float32, name=None),\n",
              "  TensorSpec(shape=(None, 20), dtype=tf.int32, name=None)))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C8fGVh8EYzO"
      },
      "source": [
        "for feature_batch, label_batch in train_data.take(1):\n",
        "    x_t = feature_batch\n",
        "    y_t = label_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyxMDqNFEYzP",
        "outputId": "20097d31-9a50-44a9-ef84-bfa782ee489b"
      },
      "source": [
        "print ('ENglish data example Shape in training set {}, GErman data example in validation set {}'.format(x_t.shape,y_t.shape))\n",
        "for feature_batch, label_batch in train_data.take(1):\n",
        "    print (label_batch)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENglish data example Shape in training set (16, 13, 128), GErman data example in validation set (16, 20)\n",
            "tf.Tensor(\n",
            "[[   1    4   18   40  368  641    9    2    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1  393    5   65   75    9    2    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1    8   35   31  116    3    2    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1    5  136    3    2    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1    4 1043   22   29    5    3    2    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1  216    8   10    3    2    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1   26 1621    6  187    3    2    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1   70  893   21  211  366    9    2    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1   13   32   62  138    3    2    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1    4   18   44   80  346    3    2    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1    5   16   34 1809    3    2    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1   10    6 3950    3    2    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1   14  197   10    3    2    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1    5   16   11  101    3    2    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1   11    6   60  398    3    2    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   1   35    8  129    7    2    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]], shape=(16, 20), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN4ULZKHEYzQ"
      },
      "source": [
        "## 3. Create the custom layer\n",
        "You will now create a custom layer to add the learned end token embedding to the encoder model:\n",
        "\n",
        "![Encoder schematic](data/neural_translation_model_encoder.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdVpwYLhEYzV"
      },
      "source": [
        "class custom_layer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, embedding_dim=128, **kwargs):\n",
        "        super(custom_layer, self).__init__(**kwargs)\n",
        "        self.end_token_E = tf.Variable(initial_value=tf.random.uniform(shape=(embedding_dim,)), trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        end_token = tf.tile(tf.reshape(self.end_token_E, shape=(1, 1, self.end_token_E.shape[0])), [tf.shape(inputs)[0],1,1])\n",
        "        return tf.keras.layers.concatenate([inputs, end_token], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CUYhNC_EYzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba232f3-b206-4203-ae2b-611795f866a9"
      },
      "source": [
        "for feature_batch, label_batch in train_data.take(1):\n",
        "    x_t = custom_layer()(feature_batch)\n",
        "    print (\"befor:\", feature_batch.shape,\"after:\",x_t.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "befor: (16, 13, 128) after: (16, 14, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2S7gW-KEYzX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYKXk29xEYzX"
      },
      "source": [
        "## 4. Build the encoder network\n",
        "The encoder network follows the schematic diagram above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D28W9IyKEYzY"
      },
      "source": [
        "def Encoder():\n",
        "    inputs = tf.keras.Input((13,128))\n",
        "    h = custom_layer()(inputs)\n",
        "    h = tf.keras.layers.Masking(mask_value=0)(h)\n",
        "    lstm, hidden_state, cell_state = tf.keras.layers.LSTM(512, return_sequences=True, return_state=True)(inputs)\n",
        "    encoder_model = tf.keras.models.Model(inputs=inputs, outputs= [hidden_state, cell_state])\n",
        "    return encoder_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsErEOXGEYzZ"
      },
      "source": [
        "for feature_batch, label_batch in train_data.take(1):\n",
        "    x_t = feature_batch\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "towRPWMqEYza",
        "outputId": "855ec56e-74ac-42f3-ba4c-f3257f3805b7"
      },
      "source": [
        "encoder=Encoder()\n",
        "hidden_state, cell_state = encoder(x_t)\n",
        "print ('encoder outputs shape:', hidden_state.shape,cell_state.shape)\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder outputs shape: (16, 512) (16, 512)\n",
            "Model: \"model_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_31 (InputLayer)        [(None, 13, 128)]         0         \n",
            "_________________________________________________________________\n",
            "lstm_76 (LSTM)               [(None, 13, 512), (None,  1312768   \n",
            "=================================================================\n",
            "Total params: 1,312,768\n",
            "Trainable params: 1,312,768\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQTZ7eEuEYzb"
      },
      "source": [
        "## 5. Build the decoder network\n",
        "The decoder network follows the schematic diagram below. \n",
        "\n",
        "![Decoder schematic](data/neural_translation_model_decoder.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTAmKZGdEYzd"
      },
      "source": [
        "class Decoder(tf.keras.models.Model):\n",
        "    def __init__(self,max_tokens):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(input_dim=max_tokens+1, output_dim=128, mask_zero=True)\n",
        "        self.lstm_layer = tf.keras.layers.LSTM(512, return_state=True, return_sequences=True)\n",
        "        self.dense_layer = tf.keras.layers.Dense(units=max_tokens+1)\n",
        "    def call(self,inputer,hidden_layer=None,cell_layer=None):\n",
        "        x=self.embedding_layer(inputer)\n",
        "        x, h, c = self.lstm_layer(x, initial_state=[hidden_layer, cell_layer])\n",
        "        x=self.dense_layer(x)\n",
        "        return x,h,c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qBwnC9_EYze"
      },
      "source": [
        "for feature_batch, label_batch in train_data.take(1):\n",
        "    x_t = feature_batch\n",
        "    y_t = label_batch\n",
        "max_tokens=len(tokenizer.index_word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY3j0ZnxEYzf",
        "outputId": "147638b4-7c10-4c06-8a3f-26d4fae0d348"
      },
      "source": [
        "hidden_state, cell_state = Encoder()(x_t)\n",
        "decoder=Decoder(max_tokens)\n",
        "output, decoder_hs, decoder_cs= decoder(y_t,hidden_state,cell_state)\n",
        "print(\"output shape:\",output.shape,\"\\n\",\"hidden shape:\",decoder_hs.shape,\"\\n\",\"cell shape:\",decoder_cs.shape)\n",
        "decoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output shape: (16, 20, 5744) \n",
            " hidden shape: (16, 512) \n",
            " cell shape: (16, 512)\n",
            "Model: \"decoder_47\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_47 (Embedding)     multiple                  735232    \n",
            "_________________________________________________________________\n",
            "lstm_80 (LSTM)               multiple                  1312768   \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             multiple                  2946672   \n",
            "=================================================================\n",
            "Total params: 4,994,672\n",
            "Trainable params: 4,994,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZpvEqhAEYzg"
      },
      "source": [
        "## 6. Make a custom training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IFPEu3dEYzg"
      },
      "source": [
        "optimizer= tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "losser = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "encoder=Encoder()\n",
        "decoder=Decoder(5743)\n",
        "@tf.function\n",
        "def loss_fn(encoder,decoder,en_input, gr_input, gr_output, loss):\n",
        "    with tf.GradientTape() as tape:\n",
        "        hidden_s, cell_s = encoder(en_input)\n",
        "        output, hidden_s, cell_s = decoder(gr_input, hidden_s,cell_s)\n",
        "        loss_value = loss(gr_output, output)\n",
        "        return loss_value, tape.gradient(loss_value, encoder.trainable_variables+decoder.trainable_variables)\n",
        "def fit_german_shape(gr):\n",
        "    input_data = gr[:,:-1]\n",
        "    output_data = gr[:,1:]\n",
        "    return input_data,output_data\n",
        "def training(train, val,optimizer, loss,epochs=5):\n",
        "    val_loss=[]\n",
        "    tr_loss=[]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        batch_num=0\n",
        "        batch_num2=0\n",
        "        epoch_loss=0\n",
        "        epoch_loss2=0\n",
        "        print (\"epoch number:\",epoch+1)\n",
        "        for english,germany in train:\n",
        "            gr_in,gr_out=fit_german_shape(germany)\n",
        "            loss1, grad= loss_fn(encoder,decoder,english, gr_in, gr_out, loss)\n",
        "            optimizer.apply_gradients(zip(grad,encoder.trainable_variables + decoder.trainable_variables))\n",
        "            epoch_loss=epoch_loss+loss1\n",
        "            batch_num=batch_num+1\n",
        "            if batch_num%100==0 : print (batch_num,\"/\",1000,\" loss: \",loss1)\n",
        "        avg_loss=epoch_loss/batch_num\n",
        "        print(\"In this train epoch, the training loss Tensor is: \"+str(avg_loss))\n",
        "        for english2,germany2 in val:\n",
        "            gr_in2,gr_out2=fit_german_shape(germany2)\n",
        "            #hidden_state,cell_state=model(en)\n",
        "            #pred,temp1,temp2=decoder(gr_in2,hidden_state,cell_state)\n",
        "            loss2, temp3 = loss_fn(encoder,decoder,english2, gr_in2, gr_out2,loss)\n",
        "            epoch_loss2=epoch_loss2+loss2\n",
        "            batch_num2=batch_num2+1\n",
        "            if batch_num2%100==0 : print (batch_num2,\"/\",250,\" loss: \",loss2)\n",
        "        avg_loss2=epoch_loss2/batch_num2\n",
        "        print(\"In this test epoch, the val-loss Tensor is: \"+str(avg_loss2))\n",
        "        val_loss.append(avg_loss2)\n",
        "        tr_loss.append(avg_loss)\n",
        "    return (tr_loss,val_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0mJqzqHEYzi",
        "outputId": "beeb5584-4352-4acd-c754-9189108f8b7f"
      },
      "source": [
        "\n",
        "history =training(train_data,test_data,optimizer,losser,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number: 1\n",
            "100 / 1000  loss:  tf.Tensor(1.4396588, shape=(), dtype=float32)\n",
            "200 / 1000  loss:  tf.Tensor(1.1045972, shape=(), dtype=float32)\n",
            "300 / 1000  loss:  tf.Tensor(1.2860949, shape=(), dtype=float32)\n",
            "400 / 1000  loss:  tf.Tensor(1.0985256, shape=(), dtype=float32)\n",
            "500 / 1000  loss:  tf.Tensor(1.2864181, shape=(), dtype=float32)\n",
            "600 / 1000  loss:  tf.Tensor(1.1528745, shape=(), dtype=float32)\n",
            "700 / 1000  loss:  tf.Tensor(1.0890355, shape=(), dtype=float32)\n",
            "800 / 1000  loss:  tf.Tensor(0.9633227, shape=(), dtype=float32)\n",
            "900 / 1000  loss:  tf.Tensor(1.0881802, shape=(), dtype=float32)\n",
            "1000 / 1000  loss:  tf.Tensor(1.0377702, shape=(), dtype=float32)\n",
            "In this train epoch, the training loss Tensor is: tf.Tensor(1.2677264, shape=(), dtype=float32)\n",
            "100 / 250  loss:  tf.Tensor(1.0909494, shape=(), dtype=float32)\n",
            "200 / 250  loss:  tf.Tensor(1.1757421, shape=(), dtype=float32)\n",
            "In this test epoch, the val-loss Tensor is: tf.Tensor(1.0694054, shape=(), dtype=float32)\n",
            "epoch number: 2\n",
            "100 / 1000  loss:  tf.Tensor(1.0330188, shape=(), dtype=float32)\n",
            "200 / 1000  loss:  tf.Tensor(0.93112123, shape=(), dtype=float32)\n",
            "300 / 1000  loss:  tf.Tensor(1.0712727, shape=(), dtype=float32)\n",
            "400 / 1000  loss:  tf.Tensor(0.9380919, shape=(), dtype=float32)\n",
            "500 / 1000  loss:  tf.Tensor(1.1024684, shape=(), dtype=float32)\n",
            "600 / 1000  loss:  tf.Tensor(0.9667465, shape=(), dtype=float32)\n",
            "700 / 1000  loss:  tf.Tensor(0.9784427, shape=(), dtype=float32)\n",
            "800 / 1000  loss:  tf.Tensor(0.8403756, shape=(), dtype=float32)\n",
            "900 / 1000  loss:  tf.Tensor(0.92732, shape=(), dtype=float32)\n",
            "1000 / 1000  loss:  tf.Tensor(0.9250248, shape=(), dtype=float32)\n",
            "In this train epoch, the training loss Tensor is: tf.Tensor(0.99169093, shape=(), dtype=float32)\n",
            "100 / 250  loss:  tf.Tensor(1.0355603, shape=(), dtype=float32)\n",
            "200 / 250  loss:  tf.Tensor(1.1508133, shape=(), dtype=float32)\n",
            "In this test epoch, the val-loss Tensor is: tf.Tensor(1.0058501, shape=(), dtype=float32)\n",
            "epoch number: 3\n",
            "100 / 1000  loss:  tf.Tensor(0.9081961, shape=(), dtype=float32)\n",
            "200 / 1000  loss:  tf.Tensor(0.85036457, shape=(), dtype=float32)\n",
            "300 / 1000  loss:  tf.Tensor(0.9806457, shape=(), dtype=float32)\n",
            "400 / 1000  loss:  tf.Tensor(0.8579763, shape=(), dtype=float32)\n",
            "500 / 1000  loss:  tf.Tensor(0.9775015, shape=(), dtype=float32)\n",
            "600 / 1000  loss:  tf.Tensor(0.8686852, shape=(), dtype=float32)\n",
            "700 / 1000  loss:  tf.Tensor(0.92128813, shape=(), dtype=float32)\n",
            "800 / 1000  loss:  tf.Tensor(0.77595097, shape=(), dtype=float32)\n",
            "900 / 1000  loss:  tf.Tensor(0.81594974, shape=(), dtype=float32)\n",
            "1000 / 1000  loss:  tf.Tensor(0.831793, shape=(), dtype=float32)\n",
            "In this train epoch, the training loss Tensor is: tf.Tensor(0.9011322, shape=(), dtype=float32)\n",
            "100 / 250  loss:  tf.Tensor(1.0309192, shape=(), dtype=float32)\n",
            "200 / 250  loss:  tf.Tensor(1.1243328, shape=(), dtype=float32)\n",
            "In this test epoch, the val-loss Tensor is: tf.Tensor(0.9836336, shape=(), dtype=float32)\n",
            "epoch number: 4\n",
            "100 / 1000  loss:  tf.Tensor(0.83632505, shape=(), dtype=float32)\n",
            "200 / 1000  loss:  tf.Tensor(0.7981125, shape=(), dtype=float32)\n",
            "300 / 1000  loss:  tf.Tensor(0.9156681, shape=(), dtype=float32)\n",
            "400 / 1000  loss:  tf.Tensor(0.79436064, shape=(), dtype=float32)\n",
            "500 / 1000  loss:  tf.Tensor(0.88124645, shape=(), dtype=float32)\n",
            "600 / 1000  loss:  tf.Tensor(0.8066862, shape=(), dtype=float32)\n",
            "700 / 1000  loss:  tf.Tensor(0.87065667, shape=(), dtype=float32)\n",
            "800 / 1000  loss:  tf.Tensor(0.71967304, shape=(), dtype=float32)\n",
            "900 / 1000  loss:  tf.Tensor(0.748246, shape=(), dtype=float32)\n",
            "1000 / 1000  loss:  tf.Tensor(0.75834054, shape=(), dtype=float32)\n",
            "In this train epoch, the training loss Tensor is: tf.Tensor(0.8323627, shape=(), dtype=float32)\n",
            "100 / 250  loss:  tf.Tensor(1.0297993, shape=(), dtype=float32)\n",
            "200 / 250  loss:  tf.Tensor(1.1113776, shape=(), dtype=float32)\n",
            "In this test epoch, the val-loss Tensor is: tf.Tensor(0.9799951, shape=(), dtype=float32)\n",
            "epoch number: 5\n",
            "100 / 1000  loss:  tf.Tensor(0.7755722, shape=(), dtype=float32)\n",
            "200 / 1000  loss:  tf.Tensor(0.74295276, shape=(), dtype=float32)\n",
            "300 / 1000  loss:  tf.Tensor(0.84708905, shape=(), dtype=float32)\n",
            "400 / 1000  loss:  tf.Tensor(0.72725886, shape=(), dtype=float32)\n",
            "500 / 1000  loss:  tf.Tensor(0.79646546, shape=(), dtype=float32)\n",
            "600 / 1000  loss:  tf.Tensor(0.75053483, shape=(), dtype=float32)\n",
            "700 / 1000  loss:  tf.Tensor(0.8160828, shape=(), dtype=float32)\n",
            "800 / 1000  loss:  tf.Tensor(0.66984165, shape=(), dtype=float32)\n",
            "900 / 1000  loss:  tf.Tensor(0.69419473, shape=(), dtype=float32)\n",
            "1000 / 1000  loss:  tf.Tensor(0.68891937, shape=(), dtype=float32)\n",
            "In this train epoch, the training loss Tensor is: tf.Tensor(0.77402604, shape=(), dtype=float32)\n",
            "100 / 250  loss:  tf.Tensor(1.0388192, shape=(), dtype=float32)\n",
            "200 / 250  loss:  tf.Tensor(1.1179912, shape=(), dtype=float32)\n",
            "In this test epoch, the val-loss Tensor is: tf.Tensor(0.983598, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMtRELm5EYzj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bd1281d3-0280-4fe9-8ff2-aa81f605e4f9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history[0])\n",
        "plt.plot(history[1])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EesuTZYNEYzj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnlkIhUvEYzk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVytecCHEYzk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH6w7XG5h-Wz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM0-QhnREYzm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK-CyD2xEYzm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}